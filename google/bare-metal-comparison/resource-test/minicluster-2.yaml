apiVersion: flux-framework.org/v1alpha1
kind: MiniCluster
metadata:
  name: flux-sample1
  namespace: flux-operator
spec:

  # Number of pods to create for MiniCluster
  # Each entire node has 88, so ask for 44 for 2 nodes
  # 88 cores * 2
  size: 2
  tasks: 88

  # This starts the flux broker without a command (interactive)
  interactive: true
  logging:
    quiet: false
    strict: false
    zeromq: true

  # Don't require one pod per node
  #pod:
  #  disableSoleTenancy: true

  # Spack installs to /opt/view, without flux-security so no imp
  flux:
    installRoot: /opt/view    
    optionFlags: "-ompi=openmpi@5 -c 1 -o cpu-affinity=per-task" 

  # This is a list because a pod can support multiple containers
  containers:
    - image: ghcr.io/rse-ops/lammps-efa-rocky:tag-8

      # working directory is important to set here, because it will be /
      # and by default we try to change permissions of what is under it
      workingDir: /opt/lammps

      # Important! If resource limits work, this should work.
      # Note the instance has 704 memory
      resources:
        limits:
          memory: "350G"
          cpu: 40

        requests:
          memory: "350G"
          cpu: 40

      # We still need to setup spack so flux can start the broker!
      commands:
        # The workers need to come up after the broker and network - we are hitting this issue
        # when we get to this larger scale (and it is compounded by the new networking issue with the service)
        # that appeared after we removed the certificate generation pod
        workerPre: sleep 60
        pre: |
          source /etc/profile.d/z10_spack_environment.sh
          asFlux="sudo -u flux -E PYTHONPATH=$PYTHONPATH -E PATH=$PATH -E FI_EFA_USE_DEVICE_RDMA=1 -E RDMAV_FORK_SAFE=1"
          . /etc/profile.d/z10_spack_environment.sh 
          cd /opt/spack-environment
          . /opt/spack-environment/spack/share/spack/setup-env.sh
          spack env activate .
          cd /opt/lammps/examples/reaxff/HNS
