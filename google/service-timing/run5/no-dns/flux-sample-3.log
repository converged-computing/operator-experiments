
Flux username: flux

Flux install root: /usr
flux user is already added.
flux user identifiers:
uid=1234(flux) gid=1234(flux) groups=1234(flux)

As Flux prefix for flux commands: sudo -u flux -E PYTHONPATH= -E PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin -E LD_LIBRARY_PATH= -E HOME=/home/flux
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
Host updating script not available yet, waiting...
# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.24.1.12	flux-sample-3.flux-service.flux-operator.svc.cluster.local	flux-sample-3
10.24.2.13 flux-sample-0.flux-service.flux-operator.svc.cluster.local flux-sample-0
10.24.3.6 flux-sample-1.flux-service.flux-operator.svc.cluster.local flux-sample-1
10.24.0.6 flux-sample-2.flux-service.flux-operator.svc.cluster.local flux-sample-2
10.24.1.12 flux-sample-3.flux-service.flux-operator.svc.cluster.local flux-sample-3

ðŸ‘‹ Hello, I'm flux-sample-3
The main host is flux-sample-0
The working directory is /opt, contents include:
/opt:
End of file listing, if you see nothing above there are no files.
flux R encode --hosts=flux-sample-[0-3] 

ðŸ“¦ Resources
{"version": 1, "execution": {"R_lite": [{"rank": "0-3", "children": {"core": "0"}}], "starttime": 0.0, "expiration": 0.0, "nodelist": ["flux-sample-[0-3]"]}}

ðŸ¸ Diagnostics: false

ðŸ¦Š Independent Minister of Privilege
[exec]
allowed-users = [ "flux", "root" ]
allowed-shells = [ "/usr/libexec/flux/flux-shell" ]

ðŸ¸ Broker Configuration
# Flux needs to know the path to the IMP executable
[exec]
imp = "/usr/libexec/flux/flux-imp"

[access]
allow-guest-user = true
allow-root-owner = true

# Point to resource definition generated with flux-R(1).
[resource]
path = "/etc/flux/system/R"

[bootstrap]
curve_cert = "/etc/curve/curve.cert"
default_port = 8050
default_bind = "tcp://eth0:%p"
default_connect = "tcp://%h.flux-service.flux-operator.svc.cluster.local:%p"
hosts = [
	{ host="flux-sample-[0-3]"},
]

[archive]
dbpath = "/var/lib/flux/job-archive.sqlite"
period = "1m"
busytimeout = "50s"
ðŸ§Šï¸ State Directory:
total 0


ðŸ”’ï¸ Working directory permissions:
total 0


âœ¨ Curve certificate generated by helper pod
#   ****  Generated on 2023-04-26 22:54:42 by CZMQ  ****
#   ZeroMQ CURVE **Secret** Certificate
#   DO NOT PROVIDE THIS FILE TO OTHER USERS nor change its permissions.
    
metadata
    name = "flux-cert-generator"
    keygen.hostname = "flux-sample-0"
curve
    public-key = "{R[Jc1hNuN}hi)a>@T-}Ln1<seB)Je2dumV1SXBF"
    secret-key = "KOX8xe[XPIXuod&)h0d2/=@JIu^(b1T0I!IIx^MH"

ðŸŒ€  flux start --wrap=strace,-e,network,-tt -o --config /etc/flux/config -Scron.directory=/etc/flux/system/cron.d   -Stbon.fanout=256   -Srundir=/run/flux    -Sstatedir=/var/lib/flux   -Slocal-uri=local:///run/flux/local -Stbon.connect_timeout=5s  -Stbon.zmqdebug=1  -Slog-stderr-level=6    -Slog-stderr-mode=local
04:41:13.066419 socket(AF_NETLINK, SOCK_RAW|SOCK_CLOEXEC, NETLINK_ROUTE) = 8
04:41:13.066592 bind(8, {sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000}, 12) = 0
04:41:13.066730 getsockname(8, {sa_family=AF_NETLINK, nl_pid=392, nl_groups=00000000}, [12]) = 0
04:41:13.066952 sendto(8, {{len=20, type=RTM_GETADDR, flags=NLM_F_REQUEST|NLM_F_DUMP, seq=1684298473, pid=0}, {ifa_family=AF_UNSPEC, ...}}, 20, 0, {sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000}, 12) = 20
04:41:13.067313 recvmsg(8, {msg_name={sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000}, msg_namelen=12, msg_iov=[{iov_base=[{{len=76, type=RTM_NEWADDR, flags=NLM_F_MULTI, seq=1684298473, pid=392}, {ifa_family=AF_INET, ifa_prefixlen=8, ifa_flags=IFA_F_PERMANENT, ifa_scope=RT_SCOPE_HOST, ifa_index=if_nametoindex("lo")}, [{{nla_len=8, nla_type=IFA_ADDRESS}, inet_addr("127.0.0.1")}, {{nla_len=8, nla_type=IFA_LOCAL}, inet_addr("127.0.0.1")}, {{nla_len=7, nla_type=IFA_LABEL}, "lo"}, {{nla_len=8, nla_type=IFA_FLAGS}, IFA_F_PERMANENT}, {{nla_len=20, nla_type=IFA_CACHEINFO}, {ifa_prefered=4294967295, ifa_valid=4294967295, cstamp=242043, tstamp=242043}}]}, {{len=88, type=RTM_NEWADDR, flags=NLM_F_MULTI, seq=1684298473, pid=392}, {ifa_family=AF_INET, ifa_prefixlen=24, ifa_flags=IFA_F_PERMANENT, ifa_scope=RT_SCOPE_UNIVERSE, ifa_index=if_nametoindex("eth0")}, [{{nla_len=8, nla_type=IFA_ADDRESS}, inet_addr("10.24.1.12")}, {{nla_len=8, nla_type=IFA_LOCAL}, inet_addr("10.24.1.12")}, {{nla_len=8, nla_type=IFA_BROADCAST}, inet_addr("10.24.1.255")}, {{nla_len=9, nla_type=IFA_LABEL}, "eth0"}, {{nla_len=8, nla_type=IFA_FLAGS}, IFA_F_PERMANENT}, {{nla_len=20, nla_type=IFA_CACHEINFO}, {ifa_prefered=4294967295, ifa_valid=4294967295, cstamp=242048, tstamp=242048}}]}], iov_len=4096}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 164
04:41:13.067691 recvmsg(8, {msg_name={sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000}, msg_namelen=12, msg_iov=[{iov_base={{len=20, type=NLMSG_DONE, flags=NLM_F_MULTI, seq=1684298473, pid=392}, 0}, iov_len=4096}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 20
04:41:13.068494 socket(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, 0) = 8
04:41:13.068595 connect(8, {sa_family=AF_UNIX, sun_path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
04:41:13.068913 socket(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, 0) = 8
04:41:13.069048 connect(8, {sa_family=AF_UNIX, sun_path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
broker.info[3]: start: none->join 2.32783ms
broker.info[3]: parent-ready: join->init 0.767748s
04:41:13.842140 socketpair(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC, 0, [22, 23]) = 0
04:41:13.842330 socketpair(AF_UNIX, SOCK_STREAM, 0, [24, 25]) = 0
04:41:13.842551 socketpair(AF_UNIX, SOCK_STREAM, 0, [26, 27]) = 0
04:41:13.842807 socketpair(AF_UNIX, SOCK_STREAM, 0, [28, 29]) = 0
broker.info[3]: configuration updated
broker.info[3]: rc1.0: running /etc/flux/rc1.d/01-sched-fluxion
broker.info[3]: rc1.0: running /etc/flux/rc1.d/02-cron
broker.info[3]: rc1.0: /etc/flux/rc1 Exited (rc=0) 0.2s
broker.info[3]: rc1-success: init->quorum 0.167681s
broker.info[3]: quorum-full: quorum->run 4.28877s
04:41:18.842557 socketpair(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC, 0, [22, 23]) = 0
04:41:18.842819 socketpair(AF_UNIX, SOCK_STREAM, 0, [24, 25]) = 0
04:41:18.843076 socketpair(AF_UNIX, SOCK_STREAM, 0, [26, 28]) = 0
04:41:18.843345 socketpair(AF_UNIX, SOCK_STREAM, 0, [58, 59]) = 0
04:41:18.843620 socketpair(AF_UNIX, SOCK_STREAM, 0, [60, 61]) = 0
broker.info[3]: shutdown: run->cleanup 11.4082s
broker.info[3]: cleanup-none: cleanup->shutdown 1.1527ms
broker.info[3]: children-none: shutdown->finalize 1.25219ms
04:41:29.711324 socketpair(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC, 0, [22, 23]) = 0
04:41:29.711598 socketpair(AF_UNIX, SOCK_STREAM, 0, [24, 25]) = 0
04:41:29.711975 socketpair(AF_UNIX, SOCK_STREAM, 0, [26, 28]) = 0
04:41:29.712267 socketpair(AF_UNIX, SOCK_STREAM, 0, [58, 59]) = 0
broker.info[3]: rc3.0: running /etc/flux/rc3.d/01-sched-fluxion
broker.info[3]: rc3.0: /etc/flux/rc3 Exited (rc=0) 0.1s
broker.info[3]: rc3-success: finalize->goodbye 0.134111s
broker.info[3]: goodbye: goodbye->exit 0.933836ms
04:41:29.855028 +++ exited with 0 +++
Return value for follower worker is 0
The follower worker exited cleanly. Goodbye!
